<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Visualizer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #fff;
            color: #000;
        }
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 100%;
            max-width: 800px;
            padding: 20px;
        }
        canvas {
            border: 1px solid #ccc;
            width: 100%;
            height: 300px;
            margin-bottom: 20px;
        }
        input[type="file"] {
            margin-bottom: 20px;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 10px;
            width: 100%;
        }
    </style>
</head>
<body>
    <div class="container">
        <canvas id="visualizer"></canvas>
        <div class="controls">
            <input type="file" id="file-input" accept="audio/*">
        </div>
    </div>

    <script>
        const fileInput = document.getElementById('file-input');
        const canvas = document.getElementById('visualizer');
        const canvasCtx = canvas.getContext('2d');

        let audioContext;
        let analyser;
        let source;
        let dataArray;
        let bufferLength;

        fileInput.addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const fileURL = URL.createObjectURL(file);
                const audio = new Audio(fileURL);
                audio.controls = true;
                document.body.appendChild(audio);

                audio.addEventListener('play', function() {
                    if (!audioContext) {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        analyser = audioContext.createAnalyser();
                        analyser.fftSize = 256;

                        bufferLength = analyser.frequencyBinCount;
                        dataArray = new Uint8Array(bufferLength);

                        source = audioContext.createMediaElementSource(audio);
                        source.connect(analyser);
                        analyser.connect(audioContext.destination);

                        visualizeParticles();
                    }
                });
            }
        });

        function visualizeParticles() {
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

            function draw() {
                requestAnimationFrame(draw);

                analyser.getByteFrequencyData(dataArray);

                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

                const particleCount = bufferLength;
                const angleStep = 2 * Math.PI / particleCount;

                for (let i = 0; i < particleCount; i++) {
                    const angle = i * angleStep;
                    const radius = dataArray[i] / 2;
                    const x = canvas.width / 2 + Math.cos(angle) * radius;
                    const y = canvas.height / 2 + Math.sin(angle) * radius;

                    canvasCtx.beginPath();
                    canvasCtx.arc(x, y, 3, 0, 2 * Math.PI);
                    canvasCtx.fillStyle = `hsl(${i * 360 / particleCount}, 100%, 60%)`;
                    canvasCtx.fill();
                }
            }

            draw();
        }
    </script>
</body>
</html>