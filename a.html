<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visualización de Audio - Nube de Puntos</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #000;
            color: #fff;
        }
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 90%;
            max-width: 800px;
            padding: 20px;
            background: #333;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.5);
        }
        canvas {
            width: 100%;
            height: 500px;
            border-radius: 8px;
        }
        input[type="file"] {
            margin-bottom: 20px;
            padding: 10px;
            border: 1px solid #444;
            border-radius: 4px;
            background: #222;
            color: #fff;
            cursor: pointer;
        }
        .controls {
            display: flex;
            justify-content: center;
            width: 100%;
            gap: 10px;
        }
        @media (max-width: 600px) {
            canvas {
                height: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <canvas id="visualizer"></canvas>
        <div class="controls">
            <input type="file" id="file-input" accept="audio/*">
        </div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        const fileInput = document.getElementById('file-input');
        const canvas = document.getElementById('visualizer');

        let scene, camera, renderer, analyser, audioContext, source;
        let points = [];

        function init3D() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, canvas.clientWidth / canvas.clientHeight, 0.1, 1000);
            camera.position.z = 5;

            renderer = new THREE.WebGLRenderer({ canvas });
            renderer.setSize(canvas.clientWidth, canvas.clientHeight);
            renderer.setPixelRatio(window.devicePixelRatio);

            // Crear nube de puntos
            const geometry = new THREE.BufferGeometry();
            const vertices = [];
            const colors = [];
            const numPoints = 128;

            for (let i = 0; i < numPoints; i++) {
                vertices.push(Math.random() * 10 - 5, Math.random() * 10 - 5, Math.random() * 10 - 5);
                colors.push(Math.random(), Math.random(), Math.random());
            }

            geometry.setAttribute('position', new THREE.Float32BufferAttribute(vertices, 3));
            geometry.setAttribute('color', new THREE.Float32BufferAttribute(colors, 3));

            const material = new THREE.PointsMaterial({ size: 0.2, vertexColors: true });
            const pointCloud = new THREE.Points(geometry, material);
            scene.add(pointCloud);
        }

        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        fileInput.addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const fileURL = URL.createObjectURL(file);
                const audio = new Audio(fileURL);
                audio.controls = true;
                document.body.appendChild(audio);

                audio.addEventListener('play', function() {
                    if (!audioContext) {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        analyser = audioContext.createAnalyser();
                        analyser.fftSize = 256;
                        analyser.smoothingTimeConstant = 0.5;

                        source = audioContext.createMediaElementSource(audio);
                        source.connect(analyser);
                        analyser.connect(audioContext.destination);

                        // Iniciar la visualización
                        init3D();
                        visualize();
                        animate();
                    }
                });
            }
        });

        function visualize() {
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            const geometry = scene.children[0].geometry;

            function update() {
                requestAnimationFrame(update);

                analyser.getByteFrequencyData(dataArray);

                const positions = geometry.attributes.position.array;
                for (let i = 0; i < dataArray.length; i++) {
                    positions[i * 3 + 1] = dataArray[i] / 10 - 5; // Ajustar la altura del punto
                }
                geometry.attributes.position.needsUpdate = true;
            }

            update();
        }
    </script>
</body>
</html>